{"cells":[{"metadata":{"_cell_guid":"da70f0c6-d80f-4dbb-8e3a-39fe1254ccb2","_uuid":"d3a0c755a06a4724396014899dae8147dbd1ffe1"},"cell_type":"markdown","source":"*This tutorial is part of the [Learn Machine Learning](https://www.kaggle.com/learn/machine-learning) series. In this step, you will learn how and why to use pipelines to clean up your modeling code.* \n\n# What Are Pipelines\n\nPipelines are a simple way to keep your data processing and modeling code organized.  Specifically, a pipeline bundles preprocessing and modeling steps so you can use the whole bundle as if it were a single step.\n\nMany data scientists hack together models without pipelines, but Pipelines have some important benefits. Those include:\n1. **Cleaner Code:** You won't need to keep track of your training (and validation) data at each step of processing.  Accounting for data at each step of processing can get messy.  With a pipeline, you don't need to manually keep track of each step.\n2. **Fewer Bugs:** There are fewer opportunities to mis-apply a step or forget a pre-processing step.\n3. **Easier to Productionize:** It can be surprisingly hard to transition a model from a prototype to something deployable at scale.  We won't go into the many related concerns here, but pipelines can help.\n4. **More Options For Model Testing:** You will see an example in the next tutorial, which covers cross-validation.\n\n---"},{"metadata":{"_cell_guid":"c7b0e891-a1fb-446d-88ef-e37ede7770b9","_uuid":"4ccf23a827e5ac3096636f0269b0acf5f3b71010"},"cell_type":"markdown","source":"# Example\n\nWe won't focus on the data loading. For now, you can imagine you are at a point where you already have train_X, test_X, train_y and test_y. "},{"metadata":{"_cell_guid":"5d4817aa-562c-4e4d-b399-e87948f67aed","_kg_hide-input":true,"_kg_hide-output":false,"_uuid":"cbc2e5c7480d82e1ae7236a3a84f7693978ec451","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read Data\ndata = pd.read_csv('../input/melb_data.csv')\ncols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\nX = data[cols_to_use]\ny = data.Price\ntrain_X, test_X, train_y, test_y = train_test_split(X, y)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"705489af-9da7-4ddc-8b12-4c1866a63cd3","_uuid":"65189c0aa62c1caa07ab967d275b2b514c23e92d"},"cell_type":"markdown","source":"\nYou have a modeling process that uses an Imputer to fill in missing values, followed by a RandomForestRegressor to make predictions.  These can be bundled together with the **make_pipeline** function as shown below."},{"metadata":{"_cell_guid":"a5100ea6-b993-4165-b856-0d600f54e292","_uuid":"cfe500eff04a4a62300a11aad88905a85010fe5f","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\n\nmy_pipeline = make_pipeline(Imputer(), RandomForestRegressor())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3e18128-551b-4fa3-8df3-ad3552919064","_uuid":"d070044f3e09d3504884831ae375194e6330bd74"},"cell_type":"markdown","source":"You can now fit and predict using this pipeline as a fused whole."},{"metadata":{"_cell_guid":"c342c433-068a-4139-9fc1-43b52f3ac54d","_kg_hide-output":false,"_uuid":"f0cebb30a6eeb31697bce34da8aac56a1b65f391","collapsed":true,"trusted":true},"cell_type":"code","source":"my_pipeline.fit(train_X, train_y)\npredictions = my_pipeline.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"456b0e66-783a-4c91-a89a-5e6171236ae6","_uuid":"799bab7dc4257efc3c85a027ff366e0902ea8796"},"cell_type":"markdown","source":"For comparison, here is the code to do the same thing without pipelines"},{"metadata":{"_cell_guid":"924b6fcb-4386-4416-a9bb-0ebe07ce8a47","_uuid":"61bf396bceda63165b820fa9b73e280457ba0314","collapsed":true,"trusted":true},"cell_type":"code","source":"my_imputer = Imputer()\nmy_model = RandomForestRegressor()\n\nimputed_train_X = my_imputer.fit_transform(train_X)\nimputed_test_X = my_imputer.transform(test_X)\nmy_model.fit(imputed_train_X, train_y)\npredictions = my_model.predict(imputed_test_X)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1d16d8ab-4476-4285-a847-3df3b7cb3fe0","_uuid":"ee84da2c54c52fdaf2540c77154425d069f47f09"},"cell_type":"markdown","source":"This particular pipeline was only a small improvement in code elegance. But pipelines become increasingly valuable as your data processing becomes increasingly sophisticated."},{"metadata":{"_cell_guid":"35ddfd5a-7003-47f6-9b6c-de98b4b6e92e","_uuid":"dd66c2728299f20056d298dad59eb3f61e5356a1"},"cell_type":"markdown","source":"# Understanding Pipelines\nMost scikit-learn objects are either **transformers** or **models.** \n\n**Transformers** are for pre-processing before modeling.  The Imputer class (for filling in missing values) is an example of a transformer.  Over time, you will learn many more transformers, and you will frequently use multiple transformers sequentially. \n\n**Models** are used to make predictions. You will usually preprocess your data (with transformers) before putting it in a model.  \n\nYou can tell if an object is a transformer or a model by how you apply it.  After fitting a transformer, you apply it with the *transform* command.  After fitting a model, you apply it with the *predict* command. Your pipeline must start with transformer steps and end with a model.  This is what you'd want anyway.\n\nEventually you will want to apply more transformers and combine them more flexibly.  We will cover this later in an Advanced Pipelines tutorial.\n\n# Your Turn\nTake your modeling code and convert it to use pipelines.  For now, you'll need to do one-hot encoding of categorical variables outside of the pipeline (i.e. before putting the data in the pipeline)."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}