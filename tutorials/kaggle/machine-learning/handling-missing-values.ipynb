{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c580981-fa5a-43a9-ae99-0251cda5b7a9",
    "_uuid": "8510ac1d600e8b4c1e27a34a84fb4cc703970d37"
   },
   "source": [
    "*This tutorial is part Level 2 in the [Learn Machine Learning](https://www.kaggle.com/learn/machine-learning) curriculum. This tutorial picks up where Level 1 finished, so you will get the most out of it if you've done the exercise from Level 1.*\n",
    "\n",
    "In this step, you will learn three approaches to dealing with missing values. You will then learn to compare the effectiveness of these approaches on any given dataset.* \n",
    "\n",
    "# Introduction\n",
    "\n",
    "There are many ways data can end up with missing values. For example\n",
    "- A 2 bedroom house wouldn't include an answer for _How large is the third bedroom_\n",
    "- Someone being surveyed may choose not to share their income\n",
    "\n",
    "Python libraries represent missing numbers as **nan** which is short for \"not a number\".  You can detect which cells have missing values, and then count how many there are in each column with the command:\n",
    "```\n",
    "print(data.isnull().sum())\n",
    "```\n",
    "\n",
    "Most libraries (including scikit-learn) will give you an error if you try to build a model using data with missing values. So you'll need to choose one of the strategies below.\n",
    "\n",
    "---\n",
    "## Solutions\n",
    "\n",
    "\n",
    "## 1) A Simple Option: Drop Columns with Missing Values\n",
    "If your data is in a DataFrame called `original_data`, you can drop columns with missing values. One way to do that is\n",
    "```\n",
    "data_without_missing_values = original_data.dropna(axis=1)\n",
    "```\n",
    "\n",
    "In many cases, you'll have both a training dataset and a test dataset.  You will want to drop the same columns in both DataFrames. In that case, you would write\n",
    "\n",
    "```\n",
    "cols_with_missing = [col for col in original_data.columns \n",
    "                                 if original_data[col].isnull().any()]\n",
    "redued_original_data = original_data.drop(cols_with_missing, axis=1)\n",
    "reduced_test_data = test_data.drop(cols_with_missing, axis=1)\n",
    "```\n",
    "If those columns had useful information (in the places that were not missing), your model loses access to this information when the column is dropped. Also, if your test data has missing values in places where your training data did not, this will result in an error.  \n",
    "\n",
    "So, it's somewhat usually not the best solution. However, it can be useful when most values in a column are missing.\n",
    "\n",
    "\n",
    "\n",
    "## 2) A Better Option: Imputation\n",
    "Imputation fills in the missing value with some number. The imputed value won't be exactly right in most cases, but it usually gives more accurate models than dropping the column entirely.\n",
    "\n",
    "This is done with\n",
    "```\n",
    "from sklearn.preprocessing import Imputer\n",
    "my_imputer = Imputer()\n",
    "data_with_imputed_values = my_imputer.fit_transform(original_data)\n",
    "```\n",
    "The default behavior fills in the mean value for imputation.  Statisticians have researched more complex strategies, but those complex strategies typically give no benefit once you plug the results into sophisticated machine learning models.\n",
    "\n",
    "One (of many) nice things about Imputation is that it can be included in a scikit-learn Pipeline. Pipelines simplify model building, model validation and model deployment.\n",
    "\n",
    "## 3) An Extension To Imputation\n",
    "Imputation is the standard approach, and it usually works well.  However, imputed values may by systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing.  Here's how it might look:\n",
    "```\n",
    "# make copy to avoid changing original data (when Imputing)\n",
    "new_data = original_data.copy()\n",
    "\n",
    "# make new columns indicating what will be imputed\n",
    "cols_with_missing = (col for col in new_data.columns \n",
    "                                 if new_data[c].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    new_data[col + '_was_missing'] = new_data[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = Imputer()\n",
    "new_data = my_imputer.fit_transform(new_data)\n",
    "```\n",
    "\n",
    "In some cases this approach will meaningfully improve results. In other cases, it doesn't help at all.\n",
    "\n",
    "---\n",
    "# Example (Comparing All Solutions)\n",
    "\n",
    "We will see am example predicting housing prices from the Melbourne Housing data.  To master missing value handling, fork this notebook and repeat the same steps with the Iowa Housing data.  Find information about both in the **Data** section of the header menu.\n",
    "\n",
    "\n",
    "### Basic Problem Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a5e604e7-3c20-409b-ad29-5c2a4fe40738",
    "_uuid": "44b399828f0b07fe63abbdcdf74bbf3b22bb8067"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "melb_data = pd.read_csv('./data/melbourne-housing-snapshot/melb_data.csv')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "melb_target = melb_data.Price\n",
    "melb_predictors = melb_data.drop(['Price'], axis=1)\n",
    "\n",
    "# For the sake of keeping the example simple, we'll use only numeric predictors. \n",
    "melb_numeric_predictors = melb_predictors.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88d1c1c9-91ba-4bef-aee5-f4a19a68e61c",
    "_uuid": "de7bdb4f005022ea45742b5d25f47cba7a6d698d"
   },
   "source": [
    "### Create Function to Measure Quality of An Approach\n",
    "We divide our data into **training** and **test**. If the reason for this is unfamiliar, review [Welcome to Data Science](https://www.kaggle.com/dansbecker/welcome-to-data-science-1).\n",
    "\n",
    "We've loaded a function `score_dataset(X_train, X_test, y_train, y_test)` to compare the quality of diffrent approaches to missing values. This function reports the out-of-sample MAE score from a RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "986dbfe4-9386-4a03-b2a4-9e99bf1b08f5",
    "_kg_hide-input": true,
    "_uuid": "6088bfdac20ece9c040e83beb28ff169d17f0666"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(melb_numeric_predictors, melb_target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7184fc99-e266-4bd7-af0d-0da9c96887f0",
    "_uuid": "df0103056e52ffb3c500f5fc1437bd175a41adad"
   },
   "source": [
    "### Get Model Score from Dropping Columns with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "64ae7a0a-95aa-47a7-aa29-a1589ebcbd18",
    "_uuid": "2957c4a7c4e6ed990b1406d5c88a9aa4c738b28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from dropping columns with Missing Values:\n",
      "350407.98017756845\n"
     ]
    }
   ],
   "source": [
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_test  = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"Mean Absolute Error from dropping columns with Missing Values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b446d3e1-0a5c-4552-8718-e07ab5f4496a",
    "_uuid": "e78f8751db60278737a388a4b85b72bed4d3f45b"
   },
   "source": [
    "### Get Model Score from Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "8cb756dc-9623-43b7-92c7-dfd87c70f450",
    "_uuid": "7f1030b598d08cd586a56d4ab33d1f99f6535784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation:\n",
      "203219.2197499547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "my_imputer = Imputer()\n",
    "\n",
    "imputed_X_train = my_imputer.fit_transform(X_train)\n",
    "imputed_X_test = my_imputer.transform(X_test)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2713edc7-a4cc-42ef-8619-bf775fa85481",
    "_uuid": "5540a5c3c2dd2fd0427820a4af57baf97729c462"
   },
   "source": [
    "### Get Score from Imputation with Extra Columns Showing What Was Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "39ba8166-9b03-41cb-9403-d728b342d5e7",
    "_uuid": "914b9e57b99d7964013f007537c300fe57e0bf91"
   },
   "outputs": [],
   "source": [
    "imputed_X_train_plus = X_train.copy()\n",
    "imputed_X_test_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns if X_train[col].isnull().any())\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n",
    "    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation while Track What Was Imputed:\n",
      "202934.97870991123\n"
     ]
    }
   ],
   "source": [
    "# Imputation\n",
    "my_imputer = Imputer()\n",
    "\n",
    "imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\n",
    "imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc678d8b-f4c9-464f-8fdf-0d69afaefcaa",
    "_uuid": "2336d82df8f643c42ecb1354c034f214e87d7aa4"
   },
   "source": [
    "# Conclusion\n",
    "In this case, the extension didn't make a big difference. As mentioned before, this can vary widely from one dataset to the next (largely determined by whether rows with missing values are intrinsically like or unlike those without missing values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8969353-a3af-4ac3-998b-b0fb884036cb",
    "_uuid": "ede373b4ec290324b175149afca77f2634a95277"
   },
   "source": [
    "# Your Turn\n",
    "1) Find some columns with missing values in your dataset.\n",
    "\n",
    "2) Use the Imputer class so you can impute missing values\n",
    "\n",
    "3) Add columns with missing values to your predictors. \n",
    "\n",
    "If you find the right columns, you may see an improvement in model scores. That said, the Iowa data doesn't have a lot of columns with missing values.  So, whether you see an improvement at this point depends on some other details of your model.\n",
    "\n",
    "Once you've added the Imputer, keep using those columns for future steps.  In the end, it will improve your model (and in most other datasets, it is a big improvement). \n",
    "\n",
    "# Keep Going\n",
    "Once you've added the Imputer and included columns with missing values, you are ready to [add categorical variables](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding), which is non-numeric data representing categories (like the name of the neighborhood a house is in).\n",
    "\n",
    "---\n",
    "\n",
    "Part of the **[Learn Machine Learning](https://www.kaggle.com/learn/machine-learning)** track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_null = [col for col in data if data[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 19 columns):\n",
      "LotFrontage     1201 non-null float64\n",
      "Alley           91 non-null object\n",
      "MasVnrType      1452 non-null object\n",
      "MasVnrArea      1452 non-null float64\n",
      "BsmtQual        1423 non-null object\n",
      "BsmtCond        1423 non-null object\n",
      "BsmtExposure    1422 non-null object\n",
      "BsmtFinType1    1423 non-null object\n",
      "BsmtFinType2    1422 non-null object\n",
      "Electrical      1459 non-null object\n",
      "FireplaceQu     770 non-null object\n",
      "GarageType      1379 non-null object\n",
      "GarageYrBlt     1379 non-null float64\n",
      "GarageFinish    1379 non-null object\n",
      "GarageQual      1379 non-null object\n",
      "GarageCond      1379 non-null object\n",
      "PoolQC          7 non-null object\n",
      "Fence           281 non-null object\n",
      "MiscFeature     54 non-null object\n",
      "dtypes: float64(3), object(16)\n",
      "memory usage: 216.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data[col_null].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grvl    50\n",
       "Pave    41\n",
       "Name: Alley, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Alley'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['SalePrice']\n",
    "\n",
    "X = data.drop(['SalePrice'], axis=1)\n",
    "X = X.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>255</td>\n",
       "      <td>20</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1957</td>\n",
       "      <td>1957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>922</td>\n",
       "      <td>...</td>\n",
       "      <td>294</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1067</td>\n",
       "      <td>60</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7837</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>639</td>\n",
       "      <td>30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8777</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1910</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1937</td>\n",
       "      <td>1950</td>\n",
       "      <td>252.0</td>\n",
       "      <td>569</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1924</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "254    255          20         70.0     8400            5            6   \n",
       "1066  1067          60         59.0     7837            6            7   \n",
       "638    639          30         67.0     8777            5            7   \n",
       "799    800          50         60.0     7200            5            7   \n",
       "380    381          50         50.0     5000            5            6   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1   ...    GarageArea  \\\n",
       "254        1957          1957         0.0         922   ...           294   \n",
       "1066       1993          1994         0.0           0   ...           380   \n",
       "638        1910          1950         0.0           0   ...             0   \n",
       "799        1937          1950       252.0         569   ...           240   \n",
       "380        1924          1950         0.0         218   ...           308   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "254          250            0              0          0            0   \n",
       "1066           0           40              0          0            0   \n",
       "638          328            0            164          0            0   \n",
       "799            0            0            264          0            0   \n",
       "380            0            0            242          0            0   \n",
       "\n",
       "      PoolArea  MiscVal  MoSold  YrSold  \n",
       "254          0        0       6    2010  \n",
       "1066         0        0       5    2009  \n",
       "638          0        0       5    2008  \n",
       "799          0        0       6    2007  \n",
       "380          0        0       5    2010  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_null = [column for column in X_train.columns if X_train[column].isnull().any()]\n",
    "col_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Score from Dropping Columns with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from dropping columns with Missing Values:\n",
      "19429.696575342467\n"
     ]
    }
   ],
   "source": [
    "reduced_X_train = X_train.drop(col_null, axis=1)\n",
    "reduced_X_test  = X_test.drop(col_null, axis=1)\n",
    "\n",
    "print(\"Mean Absolute Error from dropping columns with Missing Values:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Score from Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='median')\n",
    "\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation:\n",
      "18914.744520547945\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error from Imputation:\")\n",
    "print(score_dataset(X_train_imputed, X_test_imputed, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Score from Imputation with Extra Columns Showing What Was Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_plus = X_train.copy()\n",
    "X_test_imputed_plus = X_test.copy()\n",
    "\n",
    "cols_with_missing = (col for col in X_train.columns if X_train[col].isnull().any())\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_imputed_plus[col + '_was_missing'] = X_train_imputed_plus[col].isnull()\n",
    "    X_test_imputed_plus[col + '_was_missing'] = X_test_imputed_plus[col].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error from Imputation while Track What Was Imputed:\n",
      "19598.195547945208\n"
     ]
    }
   ],
   "source": [
    "imputer = Imputer(strategy=\"median\")\n",
    "\n",
    "X_train_imputed_plus = imputer.fit_transform(X_train_imputed_plus)\n",
    "X_test_imputed_plus = imputer.transform(X_test_imputed_plus)\n",
    "\n",
    "print(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\n",
    "print(score_dataset(X_train_imputed_plus, X_test_imputed_plus, y_train, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
